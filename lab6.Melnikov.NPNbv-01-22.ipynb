{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ЗАГРУЗКА И ПРЕДОБРАБОТКА ДАННЫХ MNIST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Загрузка данных MNIST...\")\n",
    "# Загружаем данные MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int32')\n",
    "\n",
    "# Нормализуем данные (важно для PCA)\n",
    "X = X / 255.0\n",
    "\n",
    "print(f\"Размерность данных: {X.shape}\")\n",
    "print(f\"Размерность меток: {y.shape}\")\n",
    "\n",
    "# Разделяем на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=10000, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=10000, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "print(f\"Валидационная выборка: {X_val.shape}\")\n",
    "print(f\"Тестовая выборка: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ВИЗУАЛИЗАЦИЯ ДАННЫХ\n",
    "# =============================================================================\n",
    "\n",
    "def plot_mnist_samples(X, y, num_samples=10):\n",
    "    \"\"\"Визуализация случайных образцов из датасета MNIST\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Выбираем случайные индексы\n",
    "    indices = np.random.choice(len(X), num_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        axes[i].imshow(X[idx].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f'Цифра: {y[idx]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nПримеры цифр из датасета MNIST:\")\n",
    "plot_mnist_samples(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# РЕАЛИЗАЦИЯ PCA С НУЛЯ\n",
    "# =============================================================================\n",
    "\n",
    "class my_PCA:\n",
    "    \"\"\"\n",
    "    Реализация метода главных компонент (PCA) с нуля\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=None):\n",
    "        \"\"\"\n",
    "        Инициализация PCA\n",
    "        \n",
    "        Parameters:\n",
    "        n_components (int): Количество главных компонент для сохранения\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.components = None      # Главные компоненты (собственные векторы)\n",
    "        self.explained_variance = None  # Объясненная дисперсия\n",
    "        self.mean = None            # Среднее значение для центрирования\n",
    "        self.cumulative_variance = None  # Накопленная объясненная дисперсия\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Обучение PCA на данных X\n",
    "        \n",
    "        Parameters:\n",
    "        X (ndarray): Матрица признаков формы (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        # Шаг 1: Центрирование данных\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Шаг 2: Вычисление ковариационной матрицы\n",
    "        cov_matrix = np.cov(X_centered, rowvar=False)\n",
    "        \n",
    "        # Шаг 3: Вычисление собственных векторов и значений\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "        \n",
    "        # Сортируем собственные значения и векторы по убыванию\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Сохраняем компоненты\n",
    "        if self.n_components is not None:\n",
    "            self.components = eigenvectors[:, :self.n_components]\n",
    "        else:\n",
    "            self.components = eigenvectors\n",
    "        \n",
    "        # Вычисляем объясненную дисперсию\n",
    "        total_variance = np.sum(eigenvalues)\n",
    "        self.explained_variance = eigenvalues / total_variance\n",
    "        self.cumulative_variance = np.cumsum(self.explained_variance)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Преобразование данных в пространство главных компонент\n",
    "        \n",
    "        Parameters:\n",
    "        X (ndarray): Матрица признаков формы (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        ndarray: Преобразованные данные\n",
    "        \"\"\"\n",
    "        X_centered = X - self.mean\n",
    "        return np.dot(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Обучение и преобразование данных за одну операцию\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# РЕАЛИЗАЦИЯ kNN С НУЛЯ\n",
    "# =============================================================================\n",
    "\n",
    "class my_kNN:\n",
    "    \"\"\"\n",
    "    Реализация алгоритма k-ближайших соседей (kNN) с нуля\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_neighbors=5):\n",
    "        \"\"\"\n",
    "        Инициализация kNN\n",
    "        \n",
    "        Parameters:\n",
    "        n_neighbors (int): Количество ближайших соседей для классификации\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение kNN (просто запоминаем данные)\n",
    "        \n",
    "        Parameters:\n",
    "        X (ndarray): Обучающие данные\n",
    "        y (ndarray): Метки классов\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание классов для новых данных\n",
    "        \n",
    "        Parameters:\n",
    "        X (ndarray): Данные для классификации\n",
    "        \n",
    "        Returns:\n",
    "        ndarray: Предсказанные метки классов\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            # Вычисляем расстояния до всех точек обучающей выборки\n",
    "            distances = np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))\n",
    "            \n",
    "            # Находим k ближайших соседей\n",
    "            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            \n",
    "            # Выбираем наиболее частый класс\n",
    "            most_common = Counter(nearest_labels).most_common(1)[0][0]\n",
    "            predictions.append(most_common)\n",
    "        \n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9850190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# АНАЛИЗ PCA НА ДАННЫХ MNIST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"АНАЛИЗ МЕТОДА ГЛАВНЫХ КОМПОНЕНТ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Применяем PCA ко всем компонентам для анализа\n",
    "pca_full = my_PCA()\n",
    "X_train_pca_full = pca_full.fit_transform(X_train)\n",
    "\n",
    "# График собственных значений (объясненной дисперсии)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# График 1: Объясненная дисперсия по компонентам\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, 101), pca_full.explained_variance[:100], 'b-', alpha=0.7)\n",
    "plt.xlabel('Номер главной компоненты')\n",
    "plt.ylabel('Доля объясненной дисперсии')\n",
    "plt.title('Объясненная дисперсия по компонентам')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# График 2: Накопленная объясненная дисперсия\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, 101), pca_full.cumulative_variance[:100], 'r-', alpha=0.7)\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% дисперсии')\n",
    "plt.axhline(y=0.90, color='orange', linestyle='--', label='90% дисперсии')\n",
    "plt.xlabel('Число компонент')\n",
    "plt.ylabel('Накопленная объясненная дисперсия')\n",
    "plt.title('Накопленная объясненная дисперсия')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# График 3: Увеличение для первых 50 компонент\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, 51), pca_full.cumulative_variance[:50], 'r-', alpha=0.7)\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% дисперсии')\n",
    "plt.axhline(y=0.90, color='orange', linestyle='--', label='90% дисперсии')\n",
    "plt.xlabel('Число компонент')\n",
    "plt.ylabel('Накопленная объясненная дисперсия')\n",
    "plt.title('Первые 50 компонент')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Анализ покрытия дисперсии\n",
    "print(\"\\nАнализ объясненной дисперсии:\")\n",
    "for n_comp in [2, 5, 10, 15, 20, 30, 50, 100]:\n",
    "    var_explained = pca_full.cumulative_variance[n_comp-1]\n",
    "    print(f\"Первые {n_comp:3d} компонент: {var_explained:.3f} ({var_explained*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ВИЗУАЛИЗАЦИЯ ДАННЫХ В ПРОСТРАНСТВЕ PCA\n",
    "# =============================================================================\n",
    "\n",
    "# Применяем PCA с 2 компонентами для визуализации\n",
    "pca_2d = my_PCA(n_components=2)\n",
    "X_train_2d = pca_2d.fit_transform(X_train)\n",
    "\n",
    "# Визуализация в 2D\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, \n",
    "                     cmap='tab10', alpha=0.6, s=1)\n",
    "plt.colorbar(scatter, label='Цифра')\n",
    "plt.xlabel('Первая главная компонента')\n",
    "plt.ylabel('Вторая главная компонента')\n",
    "plt.title('MNIST в пространстве первых двух главных компонент')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be9cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ТЕСТИРОВАНИЕ kNN НА ИСХОДНЫХ ДАННЫХ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ТЕСТИРОВАНИЕ kNN НА ИСХОДНЫХ ДАННЫХ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Используем подвыборку для ускорения вычислений\n",
    "sample_size = 5000\n",
    "X_train_small = X_train[:sample_size]\n",
    "y_train_small = y_train[:sample_size]\n",
    "X_val_small = X_val[:1000]\n",
    "y_val_small = y_val[:1000]\n",
    "\n",
    "# Тестируем kNN на исходных данных\n",
    "knn_original = my_kNN(n_neighbors=5)\n",
    "knn_original.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Предсказания на валидационной выборке\n",
    "y_pred_original = knn_original.predict(X_val_small)\n",
    "accuracy_original = accuracy_score(y_val_small, y_pred_original)\n",
    "\n",
    "print(f\"Точность kNN на исходных данных: {accuracy_original:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ОПТИМИЗАЦИЯ kNN С ИСПОЛЬЗОВАНИЕМ PCA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ОПТИМИЗАЦИЯ kNN С ИСПОЛЬЗОВАНИЕМ PCA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Параметры для поиска\n",
    "n_components_list = [2, 5, 10, 15, 20, 30, 50, 100]\n",
    "n_neighbors_list = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Поиск оптимальных параметров...\")\n",
    "print(\"Компоненты | Соседи | Точность\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for n_comp in n_components_list:\n",
    "    # Применяем PCA\n",
    "    pca = my_PCA(n_components=n_comp)\n",
    "    X_train_pca = pca.fit_transform(X_train_small)\n",
    "    X_val_pca = pca.transform(X_val_small)\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        # Обучаем kNN\n",
    "        knn = my_kNN(n_neighbors=n_neighbors)\n",
    "        knn.fit(X_train_pca, y_train_small)\n",
    "        \n",
    "        # Предсказания и оценка точности\n",
    "        y_pred = knn.predict(X_val_pca)\n",
    "        accuracy = accuracy_score(y_val_small, y_pred)\n",
    "        \n",
    "        results.append((n_comp, n_neighbors, accuracy))\n",
    "        \n",
    "        print(f\"{n_comp:10d} | {n_neighbors:7d} | {accuracy:.4f}\")\n",
    "        \n",
    "        # Сохраняем лучшие параметры\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'n_components': n_comp, 'n_neighbors': n_neighbors}\n",
    "\n",
    "print(f\"\\nЛучшая точность: {best_accuracy:.4f}\")\n",
    "print(f\"Лучшие параметры: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ ОПТИМИЗАЦИИ\n",
    "# =============================================================================\n",
    "\n",
    "# Преобразуем результаты в матрицу для heatmap\n",
    "accuracy_matrix = np.zeros((len(n_components_list), len(n_neighbors_list)))\n",
    "for i, n_comp in enumerate(n_components_list):\n",
    "    for j, n_neighbors in enumerate(n_neighbors_list):\n",
    "        for result in results:\n",
    "            if result[0] == n_comp and result[1] == n_neighbors:\n",
    "                accuracy_matrix[i, j] = result[2]\n",
    "\n",
    "# Heatmap точности\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(accuracy_matrix, \n",
    "            xticklabels=n_neighbors_list,\n",
    "            yticklabels=n_components_list,\n",
    "            annot=True, fmt='.3f', cmap='viridis')\n",
    "plt.xlabel('Число соседей (k)')\n",
    "plt.ylabel('Число главных компонент')\n",
    "plt.title('Точность kNN в зависимости от параметров')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# График зависимости точности от числа компонент\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Для фиксированного числа соседей (лучшего)\n",
    "best_k = best_params['n_neighbors']\n",
    "accuracies_by_components = []\n",
    "\n",
    "for n_comp in n_components_list:\n",
    "    accuracy = next((acc for comp, k, acc in results \n",
    "                    if comp == n_comp and k == best_k), 0)\n",
    "    accuracies_by_components.append(accuracy)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(n_components_list, accuracies_by_components, 'bo-', linewidth=2)\n",
    "plt.axhline(y=accuracy_original, color='r', linestyle='--', \n",
    "           label=f'Без PCA: {accuracy_original:.3f}')\n",
    "plt.xlabel('Число главных компонент')\n",
    "plt.ylabel('Точность')\n",
    "plt.title(f'Точность vs Число компонент (k={best_k})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# График зависимости точности от числа соседей\n",
    "plt.subplot(1, 2, 2)\n",
    "best_n_comp = best_params['n_components']\n",
    "accuracies_by_neighbors = []\n",
    "\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    accuracy = next((acc for comp, k, acc in results \n",
    "                    if comp == best_n_comp and k == n_neighbors), 0)\n",
    "    accuracies_by_neighbors.append(accuracy)\n",
    "\n",
    "plt.plot(n_neighbors_list, accuracies_by_neighbors, 'ro-', linewidth=2)\n",
    "plt.xlabel('Число соседей (k)')\n",
    "plt.ylabel('Точность')\n",
    "plt.title(f'Точность vs Число соседей (компоненты={best_n_comp})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189499c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ФИНАЛЬНОЕ ТЕСТИРОВАНИЕ НА ТЕСТОВОЙ ВЫБОРКЕ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ФИНАЛЬНОЕ ТЕСТИРОВАНИЕ НА ТЕСТОВОЙ ВЫБОРКЕ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Используем лучшие параметры на всей обучающей выборке\n",
    "print(\"Обучение финальной модели...\")\n",
    "\n",
    "# Применяем PCA с лучшим числом компонент\n",
    "pca_final = my_PCA(n_components=best_params['n_components'])\n",
    "X_train_final = pca_final.fit_transform(X_train)\n",
    "X_test_final = pca_final.transform(X_test)\n",
    "\n",
    "# Обучаем kNN с лучшим числом соседей\n",
    "knn_final = my_kNN(n_neighbors=best_params['n_neighbors'])\n",
    "knn_final.fit(X_train_final, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "print(\"Предсказание на тестовой выборке...\")\n",
    "y_pred_final = knn_final.predict(X_test_final)\n",
    "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"Финальная точность на тестовой выборке: {accuracy_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ВЫВОДЫ И АНАЛИЗ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ВЫВОДЫ И АНАЛИЗ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1. АНАЛИЗ PCA:\")\n",
    "print(f\"   - Первые 2 компоненты объясняют {pca_full.cumulative_variance[1]:.3f} дисперсии\")\n",
    "print(f\"   - Первые 15 компонент объясняют {pca_full.cumulative_variance[14]:.3f} дисперсии\")\n",
    "print(f\"   - Первые 50 компонент объясняют {pca_full.cumulative_variance[49]:.3f} дисперсии\")\n",
    "\n",
    "print(\"\\n2. СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
    "print(f\"   - kNN на исходных данных: {accuracy_original:.4f}\")\n",
    "print(f\"   - kNN + PCA (оптимизированный): {accuracy_final:.4f}\")\n",
    "\n",
    "improvement = accuracy_final - accuracy_original\n",
    "if improvement > 0:\n",
    "    print(f\"   - Улучшение за счет PCA: +{improvement:.4f}\")\n",
    "else:\n",
    "    print(f\"   - Потеря точности: {improvement:.4f}\")\n",
    "\n",
    "print(\"\\n3. ПРАКТИЧЕСКИЕ ПРЕИМУЩЕСТВА PCA:\")\n",
    "print(f\"   - Сокращение размерности: 784 -> {best_params['n_components']}\")\n",
    "reduction_ratio = (1 - best_params['n_components'] / 784) * 100\n",
    "print(f\"   - Сокращение на {reduction_ratio:.1f}%\")\n",
    "print(\"   - Ускорение вычислений kNN\")\n",
    "print(\"   - Уменьшение требования к памяти\")\n",
    "\n",
    "print(\"\\n4. ЛИНЕЙНАЯ РАЗДЕЛИМОСТЬ:\")\n",
    "print(\"   - Визуализация в 2D показывает частичную линейную разделимость\")\n",
    "print(\"   - Некоторые цифры (0, 1) хорошо отделимы, другие смешиваются\")\n",
    "print(\"   - Для полного разделения требуется больше компонент\")\n",
    "\n",
    "# Визуализация главных компонент\n",
    "print(\"\\nВизуализация главных компонент...\")\n",
    "def plot_principal_components(pca, n_components=10):\n",
    "    \"\"\"Визуализация первых главных компонент как изображений\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(n_components, 10)):\n",
    "        component_image = pca.components[:, i].reshape(28, 28)\n",
    "        axes[i].imshow(component_image, cmap='seismic')\n",
    "        axes[i].set_title(f'Компонента {i+1}\\n({pca.explained_variance[i]:.4f})')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_principal_components(pca_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
